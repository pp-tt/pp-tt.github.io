<!DOCTYPE html>
<html dir="ltr" lang="zh">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta content='TensorFlow 笔记（一） # 介绍TensorFlow基本API和神经网络训练的基本流程：准备数据（数据加载，数据乱序，数据分割，数据配对），搭建神经网络，参数优化，计算LOSS，计算ACC，画出LOSS和ACC图。通过鸢尾花分类串起来以上操作。
1.神经网络的计算过程 # 反向传播计算示例代码：
import tensorflow as tf w = tf.Variable(tf.constant(5, dtype=tf.float32)) # 定义可变变量 lr = 0.999 # 定义学习率 epoch = 40 # 迭代次数 for epoch in range(epoch): with tf.GradientTape() as tape: # with 结构起到grads框起了梯度的计算过程 loss = tf.square(w + 1) grads = tape.gradient(loss, w) # .gradient函数告知谁对谁求导 w.assign_sub(lr * grads) # .assign_sub 对变量做自减，即 w -= lr * grads print(f"After {epoch} epoch, w is {w.numpy()}, loss is {loss}") 2.' name="description"/>
<meta content="#FFFFFF" name="theme-color"/>
<meta content="light dark" name="color-scheme"/><meta content="" property="og:title"/>
<meta content='TensorFlow 笔记（一） # 介绍TensorFlow基本API和神经网络训练的基本流程：准备数据（数据加载，数据乱序，数据分割，数据配对），搭建神经网络，参数优化，计算LOSS，计算ACC，画出LOSS和ACC图。通过鸢尾花分类串起来以上操作。
1.神经网络的计算过程 # 反向传播计算示例代码：
import tensorflow as tf w = tf.Variable(tf.constant(5, dtype=tf.float32)) # 定义可变变量 lr = 0.999 # 定义学习率 epoch = 40 # 迭代次数 for epoch in range(epoch): with tf.GradientTape() as tape: # with 结构起到grads框起了梯度的计算过程 loss = tf.square(w + 1) grads = tape.gradient(loss, w) # .gradient函数告知谁对谁求导 w.assign_sub(lr * grads) # .assign_sub 对变量做自减，即 w -= lr * grads print(f"After {epoch} epoch, w is {w.numpy()}, loss is {loss}") 2.' property="og:description"/>
<meta content="article" property="og:type"/>
<meta content="https://pp-tt.github.io.git/notes/tensorflow/tensorflow-%E7%AC%94%E8%AE%B0%E4%B8%80/" property="og:url"/><meta content="notes" property="article:section"/>
<title>Tensor Flow 笔记（一） | 噗通 🍀</title>
<link href="/manifest.json" rel="manifest"/>
<link href="/favicon.png" rel="icon" type="image/x-icon"/>
<link crossorigin="anonymous" href="/book.min.a82d7e77ceb134d151c4d7e381eeb30623fbd5a524d58c584d8716ecec0205bd.css" integrity="sha256-qC1+d86xNNFRxNfjge6zBiP71aUk1YxYTYcW7OwCBb0=" rel="stylesheet"/>
<script defer="" src="/flexsearch.min.js"></script>
<script crossorigin="anonymous" defer="" integrity="sha256-nw8N6I2OvsU9hLjl4/Yg9dWCRNiTxySzXknGhKrOstM=" src="/zh.search.min.9f0f0de88d8ebec53d84b8e5e3f620f5d58244d893c724b35e49c684aaceb2d3.js"></script>
<script crossorigin="anonymous" defer="" integrity="sha256-b2+Q/LjrHEnsOJg45rgB0N4ZQwuOUWkC+NdcPIvZhzk=" src="/sw.min.6f6f90fcb8eb1c49ec389838e6b801d0de19430b8e516902f8d75c3c8bd98739.js"></script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
</head>
<body dir="ltr">
<input class="hidden toggle" id="menu-control" type="checkbox"/>
<input class="hidden toggle" id="toc-control" type="checkbox"/>
<main class="container flex">
<aside class="book-menu">
<div class="book-menu-content">
<nav>
<h2 class="book-brand">
<a class="flex align-center" href="/"><span>噗通 🍀</span>
</a>
</h2>
<div class="book-search">
<input aria-label="Search" data-hotkeys="s/" id="book-search-input" maxlength="64" placeholder="Search" type="text"/>
<div class="book-search-spinner hidden"></div>
<ul id="book-search-results"></ul>
</div>
<ul>
<li class="book-section-flat">
<span>--学习笔记--👇</span>
<ul>
<li>
<input class="toggle" id="section-0f70934a6e5284fbc93928c61dfe9c83" type="checkbox"/>
<label class="flex justify-between" for="section-0f70934a6e5284fbc93928c61dfe9c83">
<a class="" role="button">Java</a>
</label>
<ul>
<li>
<a class="" href="/notes/java/arraylist-%E6%89%A9%E5%AE%B9%E8%A7%84%E5%88%99/">Array List 扩容规则</a>
</li>
<li>
<a class="" href="/notes/java/hashmap-%E7%9B%B8%E5%85%B3%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/">Hash Map 相关学习总结</a>
</li>
<li>
<a class="" href="/notes/java/java-%E5%8F%8D%E5%B0%84/">Java 反射</a>
</li>
</ul>
</li>
<li>
<input class="toggle" id="section-b7444509cb631180897a34f028407c2c" type="checkbox"/>
<label class="flex justify-between" for="section-b7444509cb631180897a34f028407c2c">
<a class="" role="button">设计模式</a>
</label>
<ul>
<li>
<a class="" href="/notes/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/uml-%E5%9B%BE/">Uml 图</a>
</li>
<li>
<a class="" href="/notes/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/">设计原则</a>
</li>
<li>
<a class="" href="/notes/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/">创建型模式</a>
</li>
<li>
<a class="" href="/notes/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E7%BB%93%E6%9E%84%E5%9E%8B%E6%A8%A1%E5%BC%8F/">结构型模式</a>
</li>
<li>
<a class="" href="/notes/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%A1%8C%E4%B8%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/">行为型模式</a>
</li>
</ul>
</li>
<li>
<input class="toggle" id="section-4364152b7ab5995d509c0b7b811005c4" type="checkbox"/>
<label class="flex justify-between" for="section-4364152b7ab5995d509c0b7b811005c4">
<a class="" role="button">JVM</a>
</label>
<ul>
<li>
<a class="" href="/notes/jvm/%E4%BB%80%E4%B9%88%E6%98%AF-jvm/">什么是 Jvm</a>
</li>
<li>
<a class="" href="/notes/jvm/%E7%A8%8B%E5%BA%8F%E8%AE%A1%E6%95%B0%E5%99%A8/">程序计数器</a>
</li>
<li>
<a class="" href="/notes/jvm/%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/">虚拟机栈</a>
</li>
<li>
<a class="" href="/notes/jvm/%E6%9C%AC%E5%9C%B0%E6%96%B9%E6%B3%95%E6%A0%88-/">本地方法栈</a>
</li>
<li>
<a class="" href="/notes/jvm/%E5%A0%86/">堆</a>
</li>
<li>
<a class="" href="/notes/jvm/%E6%96%B9%E6%B3%95%E5%8C%BA/">方法区</a>
</li>
<li>
<a class="" href="/notes/jvm/%E7%9B%B4%E6%8E%A5%E5%86%85%E5%AD%98/">直接内存</a>
</li>
<li>
<a class="" href="/notes/jvm/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/">垃圾回收</a>
</li>
<li>
<a class="" href="/notes/jvm/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/">垃圾回收器</a>
</li>
</ul>
</li>
<li>
<input class="toggle" id="section-ea55243c547fa272027885b73a74852e" type="checkbox"/>
<label class="flex justify-between" for="section-ea55243c547fa272027885b73a74852e">
<a class="" role="button">嵌入式重点总结</a>
</label>
<ul>
<li>
<a class="" href="/notes/%E5%B5%8C%E5%85%A5%E5%BC%8F%E6%80%BB%E7%BB%93/c/">C</a>
</li>
<li>
<a class="" href="/notes/%E5%B5%8C%E5%85%A5%E5%BC%8F%E6%80%BB%E7%BB%93/arm/">Arm</a>
</li>
<li>
<a class="" href="/notes/%E5%B5%8C%E5%85%A5%E5%BC%8F%E6%80%BB%E7%BB%93/stm32/">Stm32</a>
</li>
</ul>
</li>
<li>
<input class="toggle" id="section-d1dc8d9746f5c776e8a82499bbb2e7c6" type="checkbox"/>
<label class="flex justify-between" for="section-d1dc8d9746f5c776e8a82499bbb2e7c6">
<a class="" role="button">BMS</a>
</label>
<ul>
<li>
<a class="" href="/notes/bms/bms-%E7%AE%80%E4%BB%8B/">Bms 简介</a>
</li>
</ul>
</li>
<li>
<input class="toggle" id="section-61661238f18c0095524962a5d1d6e676" type="checkbox"/>
<label class="flex justify-between" for="section-61661238f18c0095524962a5d1d6e676">
<a class="" role="button">Spring</a>
</label>
<ul>
<li>
<a class="" href="/notes/spring/beanfactory%E4%B8%8Eapplicationcontext/">Bean Factory与 Application Context</a>
</li>
<li>
<a class="" href="/notes/spring/nacos-%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/">Nacos 配置中心</a>
</li>
<li>
<a class="" href="/notes/spring/open-feign-%E8%BF%9C%E7%A8%8B%E8%B0%83%E7%94%A8%E7%A4%BA%E4%BE%8B/">Open Feign 远程调用示例</a>
</li>
<li>
<a class="" href="/notes/spring/springboot-%E6%95%B4%E5%90%88-mybatis-plus/">Spring Boot 整合 My Batis Plus</a>
</li>
</ul>
</li>
<li>
<input class="toggle" id="section-58f730a0b22fcdc7a886db614d77f88c" type="checkbox"/>
<label class="flex justify-between" for="section-58f730a0b22fcdc7a886db614d77f88c">
<a class="" role="button">代码随想录刷题</a>
</label>
<ul>
<li>
<a class="" href="/notes/leetcode/day001-%E7%AC%AC%E4%B8%80%E7%AB%A0%E6%95%B0%E7%BB%84/">Day001 第一章数组</a>
</li>
<li>
<a class="" href="/notes/leetcode/day002-%E7%AC%AC%E4%B8%80%E7%AB%A0%E6%95%B0%E7%BB%84/">Day002 第一章数组</a>
</li>
<li>
<a class="" href="/notes/leetcode/day003-%E7%AC%AC%E4%BA%8C%E7%AB%A0%E9%93%BE%E8%A1%A8/">Day003 第二章链表</a>
</li>
<li>
<a class="" href="/notes/leetcode/day004-%E7%AC%AC%E4%BA%8C%E7%AB%A0%E9%93%BE%E8%A1%A8/">Day004 第二章链表</a>
</li>
<li>
<a class="" href="/notes/leetcode/day006-%E7%AC%AC%E4%B8%89%E7%AB%A0%E5%93%88%E5%B8%8C%E8%A1%A8/">Day006 第三章哈希表</a>
</li>
<li>
<a class="" href="/notes/leetcode/day007-%E7%AC%AC%E4%B8%89%E7%AB%A0%E5%93%88%E5%B8%8C%E8%A1%A8/">Day007 第三章哈希表</a>
</li>
<li>
<a class="" href="/notes/leetcode/day008-%E7%AC%AC%E5%9B%9B%E7%AB%A0%E5%AD%97%E7%AC%A6%E4%B8%B2/">Day008 第四章字符串</a>
</li>
<li>
<a class="" href="/notes/leetcode/day009-%E7%AC%AC%E5%9B%9B%E7%AB%A0%E5%AD%97%E7%AC%A6%E4%B8%B2/">Day009 第四章字符串</a>
</li>
<li>
<a class="" href="/notes/leetcode/day010-%E7%AC%AC%E4%BA%94%E7%AB%A0%E6%A0%88%E4%B8%8E%E9%98%9F%E5%88%97/">Day010 第五章栈与队列</a>
</li>
<li>
<a class="" href="/notes/leetcode/day011-%E7%AC%AC%E4%BA%94%E7%AB%A0%E6%A0%88%E4%B8%8E%E9%98%9F%E5%88%97/">Day011 第五章栈与队列</a>
</li>
<li>
<a class="" href="/notes/leetcode/day013-%E7%AC%AC%E4%BA%94%E7%AB%A0%E6%A0%88%E4%B8%8E%E9%98%9F%E5%88%97/">Day013 第五章栈与队列</a>
</li>
<li>
<a class="" href="/notes/leetcode/day014-%E7%AC%AC%E5%85%AD%E7%AB%A0%E4%BA%8C%E5%8F%89%E6%A0%91/">Day014 第六章二叉树</a>
</li>
<li>
<a class="" href="/notes/leetcode/day015-%E7%AC%AC%E5%85%AD%E7%AB%A0%E4%BA%8C%E5%8F%89%E6%A0%91/">Day015 第六章二叉树</a>
</li>
<li>
<a class="" href="/notes/leetcode/day017-%E7%AC%AC%E5%85%AD%E7%AB%A0%E4%BA%8C%E5%8F%89%E6%A0%91/">Day017 第六章二叉树</a>
</li>
</ul>
</li>
<li>
<input class="toggle" id="section-4f95435d3a74007e2c985ea455bbb6e6" type="checkbox"/>
<label class="flex justify-between" for="section-4f95435d3a74007e2c985ea455bbb6e6">
<a class="" role="button">MyBatisPlus</a>
</label>
<ul>
<li>
<a class="" href="/notes/mybatisplus/%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/">MP快速入门</a>
</li>
<li>
<a class="" href="/notes/mybatisplus/%E4%B8%80%E8%88%AC%E6%9F%A5%E8%AF%A2%E6%93%8D%E4%BD%9C/">一般查询操作</a>
</li>
<li>
<a class="" href="/notes/mybatisplus/%E5%88%86%E9%A1%B5%E6%9F%A5%E8%AF%A2/">分页查询</a>
</li>
<li>
<a class="" href="/notes/mybatisplus/%E9%80%BB%E8%BE%91%E5%88%A0%E9%99%A4/">逻辑删除</a>
</li>
<li>
<a class="" href="/notes/mybatisplus/%E6%9D%A1%E4%BB%B6%E6%9F%A5%E8%AF%A2/">条件查询</a>
</li>
<li>
<a class="" href="/notes/mybatisplus/%E5%B0%81%E8%A3%85service%E4%BD%BF%E7%94%A8/">封装service使用</a>
</li>
</ul>
</li>
<li>
<input class="toggle" id="section-e2ca0d138d67d9d3ae55da25ac044829" type="checkbox"/>
<label class="flex justify-between" for="section-e2ca0d138d67d9d3ae55da25ac044829">
<a class="" role="button">Redis</a>
</label>
<ul>
<li>
<a class="" href="/notes/redis/nosql%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AE%80%E4%BB%8B/">No Sql数据库简介</a>
</li>
<li>
<a class="" href="/notes/redis/redis-key/">Redis Key</a>
</li>
<li>
<a class="" href="/notes/redis/redis-string/">Redis String</a>
</li>
<li>
<a class="" href="/notes/redis/redis-list/">Redis List</a>
</li>
<li>
<a class="" href="/notes/redis/redis-set/">Redis Set</a>
</li>
<li>
<a class="" href="/notes/redis/redis-hash/">Redis Hash</a>
</li>
<li>
<a class="" href="/notes/redis/redis-zset/">Redis Zset</a>
</li>
<li>
<a class="" href="/notes/redis/redis-%E5%8F%91%E5%B8%83%E4%B8%8E%E8%AE%A2%E9%98%85/">Redis 发布与订阅</a>
</li>
<li>
<a class="" href="/notes/redis/redis-jedis/">Redis Jedis</a>
</li>
<li>
<a class="" href="/notes/redis/springboot-%E6%95%B4%E5%90%88-redis/">Spring Boot 整合 Redis</a>
</li>
<li>
<a class="" href="/notes/redis/redis-%E4%BA%8B%E5%8A%A1%E5%92%8C%E9%94%81%E6%9C%BA%E5%88%B6/">Redis 事务和锁机制</a>
</li>
</ul>
</li>
<li>
<input checked="" class="toggle" id="section-39abd0d44427d4a54e694a2b3f22d967" type="checkbox"/>
<label class="flex justify-between" for="section-39abd0d44427d4a54e694a2b3f22d967">
<a class="" role="button">TensorFlow</a>
</label>
<ul>
<li>
<a class="active" href="/notes/tensorflow/tensorflow-%E7%AC%94%E8%AE%B0%E4%B8%80/">Tensor Flow 笔记（一）</a>
</li>
<li>
<a class="" href="/notes/tensorflow/tensorflow-%E7%AC%94%E8%AE%B0%E4%BA%8C/">Tensor Flow 笔记（二）</a>
</li>
<li>
<a class="" href="/notes/tensorflow/tensorflow-%E7%AC%94%E8%AE%B0%E4%B8%89/">Tensor Flow 笔记（三）</a>
</li>
<li>
<a class="" href="/notes/tensorflow/tensorflow-%E7%AC%94%E8%AE%B0%E5%9B%9B/">Tensor Flow 笔记（四）</a>
</li>
<li>
<a class="" href="/notes/tensorflow/tensorflow-%E7%AC%94%E8%AE%B0%E4%BA%94/">Tensor Flow 笔记（五）</a>
</li>
</ul>
</li>
<li>
<input class="toggle" id="section-3907b2cf55ed520ad784e24525c8baa4" type="checkbox"/>
<label class="flex justify-between" for="section-3907b2cf55ed520ad784e24525c8baa4">
<a class="" role="button">Swift</a>
</label>
<ul>
<li>
<a class="" href="/notes/swift/swiftui-%E5%B8%B8%E7%94%A8%E8%A7%86%E5%9B%BE-views/">Swift Ui 常用视图 Views</a>
</li>
<li>
<a class="" href="/notes/swift/swiftui-%E4%BF%A1%E6%81%AF%E8%A7%86%E5%9B%BE-views/">Swift Ui 信息视图 Views</a>
</li>
<li>
<a class="" href="/notes/swift/swiftui-%E5%B1%82%E7%BA%A7%E8%A7%86%E5%9B%BE-views/">Swift Ui 层级视图 Views</a>
</li>
<li>
<a class="" href="/notes/swift/swiftui-%E6%8E%A7%E5%88%B6%E8%A7%86%E5%9B%BE-views/">Swift Ui 控制视图 Views</a>
</li>
</ul>
</li>
<li>
<input class="toggle" id="section-a42f4efe12b0d964f8de7588b38cb659" type="checkbox"/>
<label class="flex justify-between" for="section-a42f4efe12b0d964f8de7588b38cb659">
<a class="" role="button">Java八股</a>
</label>
<ul>
<li>
<a class="" href="/notes/%E5%85%AB%E8%82%A1/%E5%B9%B6%E5%8F%91/">Concurrence</a>
</li>
<li>
<a class="" href="/notes/%E5%85%AB%E8%82%A1/mybatis/">MyBatis</a>
</li>
<li>
<a class="" href="/notes/%E5%85%AB%E8%82%A1/mysql/">MySQL</a>
</li>
<li>
<a class="" href="/notes/%E5%85%AB%E8%82%A1/jvm/">Jvm</a>
</li>
<li>
<a class="" href="/notes/%E5%85%AB%E8%82%A1/redis/">Redis</a>
</li>
</ul>
</li>
</ul>
</li>
<li class="book-section-flat">
<span>--解决方案--👇</span>
<ul>
<li>
<input class="toggle" id="section-f1d4602254471b9d0da445dd468cd456" type="checkbox"/>
<label class="flex justify-between" for="section-f1d4602254471b9d0da445dd468cd456">
<a class="" role="button">环境配置</a>
</label>
<ul>
<li>
<a class="" href="/solution/environment/apple-m%E7%B3%BB%E5%88%97%E8%8A%AF%E7%89%87%E5%AE%89%E8%A3%85-pyqt/">Apple M系列芯片安装 Pyqt</a>
</li>
<li>
<a class="" href="/solution/environment/docker-%E5%AE%89%E8%A3%85-redis-/">Docker 安装 Redis</a>
</li>
<li>
<a class="" href="/solution/environment/hugo-%E4%B8%BB%E9%A2%98-hugo-book-%E4%B8%AD%E8%8B%B1%E6%96%87%E6%90%9C%E7%B4%A2%E9%85%8D%E7%BD%AE/">Hugo 主题 Hugo Book 中英文搜索配置</a>
</li>
<li>
<a class="" href="/solution/environment/iterm2-oh-my-zsh-%E9%85%8D%E7%BD%AE/">I Term2 Oh My Zsh 配置</a>
</li>
<li>
<a class="" href="/solution/environment/m1-%E8%8A%AF%E7%89%87-docker-%E5%AE%89%E8%A3%85-mysql5.7-/">M1 芯片 Docker 安装 Mysql5.7</a>
</li>
<li>
<a class="" href="/solution/environment/mac-idea-%E5%BF%AB%E6%8D%B7%E9%94%AE%E4%BD%8D/">MAC Idea 快捷键位</a>
</li>
<li>
<a class="" href="/solution/environment/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/">内网穿透</a>
</li>
<li>
<a class="" href="/solution/environment/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F%E7%9A%84%E8%87%AA%E5%90%AF%E5%8A%A8%E8%AE%BE%E7%BD%AE/">内网穿透的自启动设置</a>
</li>
</ul>
</li>
<li>
<input class="toggle" id="section-5a76a664ba4855b79d3c1bc77e5b08b1" type="checkbox"/>
<label class="flex justify-between" for="section-5a76a664ba4855b79d3c1bc77e5b08b1">
<a class="" role="button">杂乱问题</a>
</label>
<ul>
<li>
<a class="" href="/solution/problems/brew-%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/">Brew 一些常用命令</a>
</li>
<li>
<a class="" href="/solution/problems/docker-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/">Docker 常用命令</a>
</li>
<li>
<a class="" href="/solution/problems/git-github-%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/">Git Git Hub 相关命令整理</a>
</li>
<li>
<a class="" href="/solution/problems/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%89%AB%E7%9B%B2/">面试题扫盲</a>
</li>
</ul>
</li>
</ul>
</li>
<li class="book-section-flat">
<span>--其他记录--👇</span>
<ul>
<li>
<input class="toggle" id="section-9ef4d2063ddc9af7785b193647f22260" type="checkbox"/>
<label class="flex justify-between" for="section-9ef4d2063ddc9af7785b193647f22260">
<a class="" role="button">我和阿刁</a>
</label>
<ul>
<li>
<a class="" href="/daily/ad/%E5%85%B3%E4%BA%8E%E9%98%BF%E5%88%812022%E5%B9%B4%E7%9A%84%E7%94%9F%E6%97%A5%E7%9A%84%E5%B0%8F%E8%AE%BA%E6%96%87/">关于阿刁2022年的生日的小论文</a>
</li>
<li>
<a class="" href="/daily/ad/%E5%85%B3%E4%BA%8E%E9%98%BF%E5%88%81%E7%9A%842021%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/">关于阿刁的2021年度总结</a>
</li>
<li>
<a class="" href="/daily/ad/%E5%85%B3%E4%BA%8E%E9%98%BF%E5%88%81%E7%9A%842022%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/">关于阿刁的2022年度总结</a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
<script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>
</div>
</aside>
<div class="book-page">
<header class="book-header">
<div class="flex align-center justify-between">
<label for="menu-control">
<img alt="Menu" class="book-icon" src="/svg/menu.svg"/>
</label>
<strong>Tensor Flow 笔记（一）</strong>
<label for="toc-control">
<img alt="Table of Contents" class="book-icon" src="/svg/toc.svg"/>
</label>
</div>
<aside class="hidden clearfix">
<nav id="TableOfContents">
<ul>
<li><a href="#tensorflow-笔记一">TensorFlow 笔记（一）</a>
<ul>
<li>
<ul>
<li>
<ul>
<li><a href="#1神经网络的计算过程">1.神经网络的计算过程</a></li>
<li><a href="#2张量生成">2.张量生成</a>
<ul>
<li><a href="#21-创建一个张量">2.1 创建一个张量</a></li>
</ul>
</li>
<li><a href="#22-numpy-转-tensor">2.2 numpy 转 Tensor</a></li>
<li><a href="#23-0张量1张量和指定值张量">2.3 <code>0</code>张量、<code>1</code>张量和指定值张量</a></li>
<li><a href="#24-其他张量">2.4 其他张量</a></li>
<li><a href="#3常用函数">3.常用函数</a></li>
<li><a href="#4-鸢尾花分类">4. 鸢尾花分类</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</aside>
</header>
<article class="markdown"><h1 id="tensorflow-笔记一">
  TensorFlow 笔记（一）
  <a class="anchor" href="#tensorflow-%e7%ac%94%e8%ae%b0%e4%b8%80">#</a>
</h1>
<p>介绍<code>TensorFlow</code>基本API和神经网络训练的基本流程：准备数据（数据加载，数据乱序，数据分割，数据配对），搭建神经网络，参数优化，计算LOSS，计算ACC，画出LOSS和ACC图。通过鸢尾花分类串起来以上操作。</p>
<h4 id="1神经网络的计算过程">
  1.神经网络的计算过程
  <a class="anchor" href="#1%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e7%9a%84%e8%ae%a1%e7%ae%97%e8%bf%87%e7%a8%8b">#</a>
</h4>
<p>反向传播计算示例代码：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> tensorflow <span style="color:#66d9ef">as</span> tf
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>w <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>Variable(tf<span style="color:#f92672">.</span>constant(<span style="color:#ae81ff">5</span>, dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32))   <span style="color:#75715e"># 定义可变变量</span>
</span></span><span style="display:flex;"><span>lr <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.999</span>    <span style="color:#75715e"># 定义学习率</span>
</span></span><span style="display:flex;"><span>epoch <span style="color:#f92672">=</span> <span style="color:#ae81ff">40</span>  <span style="color:#75715e"># 迭代次数</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(epoch):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>GradientTape() <span style="color:#66d9ef">as</span> tape: <span style="color:#75715e"># with 结构起到grads框起了梯度的计算过程</span>
</span></span><span style="display:flex;"><span>        loss <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>square(w <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>    grads <span style="color:#f92672">=</span> tape<span style="color:#f92672">.</span>gradient(loss, w)  <span style="color:#75715e"># .gradient函数告知谁对谁求导</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    w<span style="color:#f92672">.</span>assign_sub(lr <span style="color:#f92672">*</span> grads) <span style="color:#75715e"># .assign_sub 对变量做自减，即 w -= lr * grads</span>
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">"After </span><span style="color:#e6db74">{</span>epoch<span style="color:#e6db74">}</span><span style="color:#e6db74"> epoch, w is </span><span style="color:#e6db74">{</span>w<span style="color:#f92672">.</span>numpy()<span style="color:#e6db74">}</span><span style="color:#e6db74">, loss is </span><span style="color:#e6db74">{</span>loss<span style="color:#e6db74">}</span><span style="color:#e6db74">"</span>)
</span></span></code></pre></div><h4 id="2张量生成">
  2.张量生成
  <a class="anchor" href="#2%e5%bc%a0%e9%87%8f%e7%94%9f%e6%88%90">#</a>
</h4>
<h5 id="21-创建一个张量">
  2.1 创建一个张量
  <a class="anchor" href="#21-%e5%88%9b%e5%bb%ba%e4%b8%80%e4%b8%aa%e5%bc%a0%e9%87%8f">#</a>
</h5>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span>a <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>constant([<span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">6</span>], dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>int16)
</span></span><span style="display:flex;"><span>print(a)    <span style="color:#75715e"># 详细显示，值、形状、类型</span>
</span></span><span style="display:flex;"><span>print(a<span style="color:#f92672">.</span>shape)  <span style="color:#75715e"># 形状</span>
</span></span><span style="display:flex;"><span>print(a<span style="color:#f92672">.</span>dtype)  <span style="color:#75715e"># 类型</span>
</span></span></code></pre></div><h4 id="22-numpy-转-tensor">
  2.2 numpy 转 Tensor
  <a class="anchor" href="#22-numpy-%e8%bd%ac-tensor">#</a>
</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>convert_to_tensor(数据名, dtype<span style="color:#f92672">=</span>数据类型)
</span></span></code></pre></div><h4 id="23-0张量1张量和指定值张量">
  2.3 <code>0</code>张量、<code>1</code>张量和指定值张量
  <a class="anchor" href="#23-0%e5%bc%a0%e9%87%8f1%e5%bc%a0%e9%87%8f%e5%92%8c%e6%8c%87%e5%ae%9a%e5%80%bc%e5%bc%a0%e9%87%8f">#</a>
</h4>
<ul>
<li>创建全为0的张量：<code>tf.zeros(维度)</code></li>
<li>创建全为1的张量：<code>tf.ones(维度)</code></li>
<li>创建全为指定值的张量：<code>tf.fill(维度， 指定值)</code></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span>a <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>zeros([<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>])
</span></span><span style="display:flex;"><span>b <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>ones(<span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>c <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>fill([<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>], <span style="color:#ae81ff">9</span>)
</span></span></code></pre></div><h4 id="24-其他张量">
  2.4 其他张量
  <a class="anchor" href="#24-%e5%85%b6%e4%bb%96%e5%bc%a0%e9%87%8f">#</a>
</h4>
<ul>
<li>生成正态分布随机数：</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(维度, mean<span style="color:#f92672">=</span>均值, stddev<span style="color:#f92672">=</span>标准差)
</span></span></code></pre></div><ul>
<li>生成截断式正态分布随机数：</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>truncated_normal(维度, mean<span style="color:#f92672">=</span>均值, stddev<span style="color:#f92672">=</span>标准差)
</span></span></code></pre></div><ul>
<li>生成均匀分布随机数 [minval, maxval]</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>uniform(维度, minval<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, maxval<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span></code></pre></div><h4 id="3常用函数">
  3.常用函数
  <a class="anchor" href="#3%e5%b8%b8%e7%94%a8%e5%87%bd%e6%95%b0">#</a>
</h4>
<ul>
<li>强制<code>tensor</code>类型转为该数据类型：</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>cast(张量名<span style="color:#960050;background-color:#1e0010">，</span>dtype<span style="color:#f92672">=</span>数据类型)
</span></span></code></pre></div><ul>
<li>计算张量维度上的元素最小值：</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>reduce_min(张量名<span style="color:#960050;background-color:#1e0010">，</span> axis<span style="color:#f92672">=</span>轴)
</span></span></code></pre></div><ul>
<li>计算张量维度上的元素最大值：</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>reduce_max(张量名<span style="color:#960050;background-color:#1e0010">，</span> axis<span style="color:#f92672">=</span>轴)
</span></span></code></pre></div><ul>
<li>计算张量维度上的平均值：</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>reduce_mean(张量名<span style="color:#960050;background-color:#1e0010">，</span> axis<span style="color:#f92672">=</span>轴)
</span></span></code></pre></div><ul>
<li>计算张量维度上的和：</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>reduce_sum(张量名, axis<span style="color:#f92672">=</span>轴)
</span></span></code></pre></div><ul>
<li>将变量标记为可训练，被标记的变量会在反向传播中记录梯度信息。神经网络中，常用该函数标记待训练参数。</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>Variable(tf<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal([<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>], mean<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, stddev<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>))
</span></span></code></pre></div><ul>
<li>实现两个张量的对应元素相加（注：只有维度相同才可以做四则运算）</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>add(张量1<span style="color:#960050;background-color:#1e0010">，</span> 张量2)
</span></span></code></pre></div><ul>
<li>实现两个张量的对应元素相减</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>subtract(张量1<span style="color:#960050;background-color:#1e0010">，</span> 张量2)
</span></span></code></pre></div><ul>
<li>实现两个张量的对应元素相乘</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>multiply(张量1<span style="color:#960050;background-color:#1e0010">，</span> 张量2)
</span></span></code></pre></div><ul>
<li>实现两个张量的对应元素相除</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>divide(张量1<span style="color:#960050;background-color:#1e0010">，</span> 张量2)
</span></span></code></pre></div><ul>
<li>计算某个张量的平方</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>square(张量名)
</span></span></code></pre></div><ul>
<li>计算某个张量的n次方</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>pow(张量名<span style="color:#960050;background-color:#1e0010">，</span> n次方数)
</span></span></code></pre></div><ul>
<li>计算某个张量的开方</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>sqrt(张量名)
</span></span></code></pre></div><ul>
<li>实现两个矩阵相乘</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>matmul(矩阵1<span style="color:#960050;background-color:#1e0010">，</span> 矩阵2)
</span></span></code></pre></div><ul>
<li>构建数据集（numpy 和 tensor 都可以用该语句）</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>Dataset<span style="color:#f92672">.</span>from_tensor_slices((输入特征<span style="color:#960050;background-color:#1e0010">，</span>标签))
</span></span></code></pre></div><ul>
<li>求导</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>GradientTape() <span style="color:#66d9ef">as</span> tape:
</span></span><span style="display:flex;"><span>  若干计算过程
</span></span><span style="display:flex;"><span>grad <span style="color:#f92672">=</span> tape<span style="color:#f92672">.</span>gradient(函数<span style="color:#960050;background-color:#1e0010">，</span>对谁求导)
</span></span></code></pre></div><ul>
<li>将数据转为 one-hot 形式的数据输出</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>one_hot(待转换数据<span style="color:#960050;background-color:#1e0010">，</span>depth<span style="color:#f92672">=</span>几分类)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>例<span style="color:#960050;background-color:#1e0010">：</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> tensorflow <span style="color:#66d9ef">as</span> tf
</span></span><span style="display:flex;"><span>labels <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>constant([<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">2</span>])
</span></span><span style="display:flex;"><span>classes <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>
</span></span><span style="display:flex;"><span>ouput <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>one_hot(labels, depth<span style="color:#f92672">=</span>classes)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">&lt;</span>tf<span style="color:#f92672">.</span>Tensor: shape<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), dtype<span style="color:#f92672">=</span>float32, numpy<span style="color:#f92672">=</span>
</span></span><span style="display:flex;"><span>array([[<span style="color:#ae81ff">0.</span>, <span style="color:#ae81ff">1.</span>, <span style="color:#ae81ff">0.</span>],
</span></span><span style="display:flex;"><span>       [<span style="color:#ae81ff">1.</span>, <span style="color:#ae81ff">0.</span>, <span style="color:#ae81ff">0.</span>],
</span></span><span style="display:flex;"><span>       [<span style="color:#ae81ff">0.</span>, <span style="color:#ae81ff">0.</span>, <span style="color:#ae81ff">1.</span>]], dtype<span style="color:#f92672">=</span>float32)<span style="color:#f92672">&gt;</span>
</span></span></code></pre></div><ul>
<li>使 n 个分类的 n 个输出符合概率分布</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>softmax()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>y <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>constant([<span style="color:#ae81ff">1.01</span>, <span style="color:#ae81ff">2.01</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">0.66</span>])
</span></span><span style="display:flex;"><span>y_pro <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>softmax(y)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">"After sotfmax, y_pro is:"</span>, y_pro)
</span></span></code></pre></div><ul>
<li>赋值操作，更新函数的值并返回，<em>调用<code>assign_sub</code>前，先用<code>tf.Variable</code>定义变量 <code>w</code> 为可训练（可自更新）</em></li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span>w<span style="color:#f92672">.</span>assign_sub(w 要自减的内容)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>例<span style="color:#960050;background-color:#1e0010">：</span>
</span></span><span style="display:flex;"><span>w <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>Variable(<span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>w<span style="color:#f92672">.</span>assign_sub(<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>print(w)
</span></span></code></pre></div><ul>
<li>返回张量沿指定维度最大值的索引</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>argmax(张量名<span style="color:#960050;background-color:#1e0010">，</span>axis<span style="color:#f92672">=</span>轴)
</span></span></code></pre></div><h4 id="4-鸢尾花分类">
  4. 鸢尾花分类
  <a class="anchor" href="#4-%e9%b8%a2%e5%b0%be%e8%8a%b1%e5%88%86%e7%b1%bb">#</a>
</h4>
<p>​	鸢尾花分类主要分为以下步骤：</p>
<ol>
<li>准备数据
<ul>
<li>数据集读入</li>
<li>数据集乱序</li>
<li>生成训练集和测试集（即 x_train / y_train）</li>
<li>配成（输入特征，标签）对，每次读入一小撮（batch）</li>
</ul>
</li>
<li>搭建网络
<ul>
<li>定义神经网络中所有可训练参数</li>
</ul>
</li>
<li>参数优化
<ul>
<li>嵌套循环迭代，with 结构更新参数，显示当前 loss</li>
</ul>
</li>
<li>测试效果
<ul>
<li>计算当前参数前向传播后的准确率，显示当前 acc</li>
</ul>
</li>
<li>acc / loss 可视化</li>
</ol>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> sklearn.datasets <span style="color:#66d9ef">as</span> datasets
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> tensorflow <span style="color:#66d9ef">as</span> tf
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">"""
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">准备数据
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">"""</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 加载数据</span>
</span></span><span style="display:flex;"><span>x_data <span style="color:#f92672">=</span> datasets<span style="color:#f92672">.</span>load_iris()<span style="color:#f92672">.</span>data
</span></span><span style="display:flex;"><span>y_data <span style="color:#f92672">=</span> datasets<span style="color:#f92672">.</span>load_iris()<span style="color:#f92672">.</span>target
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 数据集乱序</span>
</span></span><span style="display:flex;"><span>np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>seed(<span style="color:#ae81ff">116</span>)  <span style="color:#75715e"># 使用相同的 seed, 使输入特征/标签一一对应</span>
</span></span><span style="display:flex;"><span>np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>shuffle(x_data)
</span></span><span style="display:flex;"><span>np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>seed(<span style="color:#ae81ff">116</span>)
</span></span><span style="display:flex;"><span>np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>shuffle(y_data)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 将数据集分为训练集和测试集</span>
</span></span><span style="display:flex;"><span>x_train <span style="color:#f92672">=</span> x_data[:<span style="color:#f92672">-</span><span style="color:#ae81ff">30</span>]
</span></span><span style="display:flex;"><span>y_train <span style="color:#f92672">=</span> y_data[:<span style="color:#f92672">-</span><span style="color:#ae81ff">30</span>]
</span></span><span style="display:flex;"><span>x_test <span style="color:#f92672">=</span> x_data[<span style="color:#f92672">-</span><span style="color:#ae81ff">30</span>:]
</span></span><span style="display:flex;"><span>y_test <span style="color:#f92672">=</span> y_data[<span style="color:#f92672">-</span><span style="color:#ae81ff">30</span>:]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 数据类型转换，否则后面矩阵相乘时会因数据类型不一致报错</span>
</span></span><span style="display:flex;"><span>x_train <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>cast(x_train, tf<span style="color:#f92672">.</span>float32)
</span></span><span style="display:flex;"><span>x_test <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>cast(x_test, tf<span style="color:#f92672">.</span>float32)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 配成 [输入特征， 标签] 对， 每次喂入一小撮（batch）</span>
</span></span><span style="display:flex;"><span>train_db <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>Dataset<span style="color:#f92672">.</span>from_tensor_slices((x_train, y_train))<span style="color:#f92672">.</span>batch(<span style="color:#ae81ff">32</span>)
</span></span><span style="display:flex;"><span>test_db <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>Dataset<span style="color:#f92672">.</span>from_tensor_slices((x_test, y_test))<span style="color:#f92672">.</span>batch(<span style="color:#ae81ff">32</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">"""
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">搭建网络
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">"""</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 生成神经网络的参数，4个输入特征，故输入层为4个输入节点，因为3分类，故输出为3个神经元</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 定义神经网络中所有可训练参数</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 使用 seed 使每次生成的随机数都相同（方便教学，使大家结果都一致，现实使用时可以不写seed）</span>
</span></span><span style="display:flex;"><span>w1 <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>Variable(tf<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>truncated_normal([<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">3</span>], stddev<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, seed<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>b1 <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>Variable(tf<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>truncated_normal([<span style="color:#ae81ff">3</span>], stddev<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, seed<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#e6db74">"""
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">参数优化
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">"""</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 定义超参数</span>
</span></span><span style="display:flex;"><span>lr <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.1</span>
</span></span><span style="display:flex;"><span>train_loss_results <span style="color:#f92672">=</span> [] <span style="color:#75715e"># 将每轮的loss记录在此列表中，为后续画 loss 曲线提供数据</span>
</span></span><span style="display:flex;"><span>test_acc <span style="color:#f92672">=</span> [] <span style="color:#75715e"># 将每轮的 acc 记录在此列表中， 为后续画 acc 曲线提供数据</span>
</span></span><span style="display:flex;"><span>epoch <span style="color:#f92672">=</span> <span style="color:#ae81ff">500</span> <span style="color:#75715e"># 循环 500 轮</span>
</span></span><span style="display:flex;"><span>loss_all <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span> <span style="color:#75715e"># 每轮分4个step， loss_all 记录四个 step 生成的 4 个 loss 的和</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 嵌套循环迭代，with 结构参数更新，显示当前 loss</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(epoch): <span style="color:#75715e"># 数据集级别迭代</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> step, (x_train, y_train) <span style="color:#f92672">in</span> enumerate(train_db): <span style="color:#75715e"># batch 级别迭代</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> tf<span style="color:#f92672">.</span>GradientTape() <span style="color:#66d9ef">as</span> tape: <span style="color:#75715e"># 记录梯度信息</span>
</span></span><span style="display:flex;"><span>            y <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>matmul(x_train, w1) <span style="color:#f92672">+</span> b1 <span style="color:#75715e"># 神经网络乘加运算</span>
</span></span><span style="display:flex;"><span>            y <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>softmax(y)    <span style="color:#75715e"># 使输出y符合概率分布</span>
</span></span><span style="display:flex;"><span>            y_ <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>one_hot(y_train, depth<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>)   <span style="color:#75715e"># 将标签值转换为独热编码</span>
</span></span><span style="display:flex;"><span>            loss <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>reduce_mean(tf<span style="color:#f92672">.</span>square(y_ <span style="color:#f92672">-</span> y)) <span style="color:#75715e"># 采用均方误差损失函数</span>
</span></span><span style="display:flex;"><span>            loss_all <span style="color:#f92672">+=</span> loss<span style="color:#f92672">.</span>numpy() <span style="color:#75715e"># 将每个 step 计算出的 loss 累加， 为后续求平均值提供数据</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 计算各个参数的梯度</span>
</span></span><span style="display:flex;"><span>        grads <span style="color:#f92672">=</span> tape<span style="color:#f92672">.</span>gradient(loss, [w1, b1])
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 参数自更新</span>
</span></span><span style="display:flex;"><span>        w1<span style="color:#f92672">.</span>assign_sub(lr <span style="color:#f92672">*</span> grads[<span style="color:#ae81ff">0</span>]) 
</span></span><span style="display:flex;"><span>        b1<span style="color:#f92672">.</span>assign_sub(lr <span style="color:#f92672">*</span> grads[<span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">"Epoch </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">, loss: </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">"</span><span style="color:#f92672">.</span>format(epoch, loss_all<span style="color:#f92672">/</span><span style="color:#ae81ff">4</span>))
</span></span><span style="display:flex;"><span>    train_loss_results<span style="color:#f92672">.</span>append(loss_all <span style="color:#f92672">/</span> <span style="color:#ae81ff">4</span>)  <span style="color:#75715e"># 将 4 个 step 的 loss 求平均记录在此变量中</span>
</span></span><span style="display:flex;"><span>    loss_all <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>    <span style="color:#75715e"># loss 归零， 为计算下一个 epoch 作准备</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">"""测试部分"""</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># total_correct 为预测对的样本个数，total_number 为测试的总样本数</span>
</span></span><span style="display:flex;"><span>    total_correct, total_number <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> x_test, y_test <span style="color:#f92672">in</span> test_db:
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># 使用更新后的参数进行预测</span>
</span></span><span style="display:flex;"><span>        y <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>matmul(x_test, w1) <span style="color:#f92672">+</span> b1
</span></span><span style="display:flex;"><span>        y <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>softmax(y)
</span></span><span style="display:flex;"><span>        pred <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>argmax(y, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        pred <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>cast(pred, dtype<span style="color:#f92672">=</span>y_test<span style="color:#f92672">.</span>dtype)
</span></span><span style="display:flex;"><span>        correct <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>cast(tf<span style="color:#f92672">.</span>equal(pred, y_test), dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>float32)
</span></span><span style="display:flex;"><span>        correct <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>reduce_sum(correct)
</span></span><span style="display:flex;"><span>        total_correct <span style="color:#f92672">+=</span> int(correct)
</span></span><span style="display:flex;"><span>        total_number <span style="color:#f92672">+=</span> x_test<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    acc <span style="color:#f92672">=</span> total_correct <span style="color:#f92672">/</span> total_number
</span></span><span style="display:flex;"><span>    test_acc<span style="color:#f92672">.</span>append(acc)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">"Test_acc:"</span>, acc)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">"---------------------"</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 绘制 loss 曲线</span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">'Loss Function Curve'</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">'Epoch'</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">'Loss'</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(train_loss_results, label<span style="color:#f92672">=</span><span style="color:#e6db74">'$LOSS$'</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>legend()
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 绘制 Accuracy 曲线</span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">'Acc Curve'</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">'Epoch'</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">'Acc'</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(test_acc, label<span style="color:#f92672">=</span><span style="color:#e6db74">"$Accuracy$"</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>legend()
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div></article>
<footer class="book-footer">
<div class="flex flex-wrap justify-between">
</div>
<script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>
</footer>
<div class="book-comments">
</div>
<label class="hidden book-menu-overlay" for="menu-control"></label>
</div>
<aside class="book-toc">
<div class="book-toc-content">
<nav id="TableOfContents">
<ul>
<li><a href="#tensorflow-笔记一">TensorFlow 笔记（一）</a>
<ul>
<li>
<ul>
<li>
<ul>
<li><a href="#1神经网络的计算过程">1.神经网络的计算过程</a></li>
<li><a href="#2张量生成">2.张量生成</a>
<ul>
<li><a href="#21-创建一个张量">2.1 创建一个张量</a></li>
</ul>
</li>
<li><a href="#22-numpy-转-tensor">2.2 numpy 转 Tensor</a></li>
<li><a href="#23-0张量1张量和指定值张量">2.3 <code>0</code>张量、<code>1</code>张量和指定值张量</a></li>
<li><a href="#24-其他张量">2.4 其他张量</a></li>
<li><a href="#3常用函数">3.常用函数</a></li>
<li><a href="#4-鸢尾花分类">4. 鸢尾花分类</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</aside>
</main>
</body>
</html>
